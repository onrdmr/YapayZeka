{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('osuDataset.csv')\n",
    "print(df.shape)\n",
    "df['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"mode == 'osu' and ranked == 1\")\n",
    "print(df.shape)\n",
    "df['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['difficulty_rating']\n",
    "x_ = df[['hit_length','cs','drain','ar','accuracy','bpm']]\n",
    "x_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x_)\n",
    "pd.DataFrame(x).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = y.to_numpy()\n",
    "plt.scatter(range(len(y_)), y_)#np.sort(y_))\n",
    "plt.xticks(range(0, len(y_),int(len(y_)/20)))\n",
    "plt.title(\"Ground Truth Diffuculty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_,bins=30)\n",
    "plt.title(\"Difficulty Rate Histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_lenght = x[:,0]\n",
    "plt.xticks(range(0, len(hit_lenght),int(len(hit_lenght)/20)))\n",
    "plt.scatter(range(len(hit_lenght)), x[:,0])\n",
    "plt.title(\"hit length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = x[:,1]\n",
    "plt.xticks(range(0, len(cs),int(len(cs)/20)))\n",
    "plt.scatter(range(len(cs)), cs)\n",
    "plt.title(\"Circle Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain = x[:,2]\n",
    "plt.xticks(range(0, len(drain),int(len(drain)/20)))\n",
    "plt.scatter(range(len(drain)), drain)\n",
    "plt.title(\"drain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = x[:,3]\n",
    "plt.xticks(range(0, len(ar),int(len(ar)/20)))\n",
    "plt.scatter(range(len(ar)), ar)\n",
    "plt.title(\"Approach Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = x[:,4]\n",
    "plt.xticks(range(0, len(acc),int(len(acc)/20)))\n",
    "plt.scatter(range(len(acc)), acc)\n",
    "plt.title(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm = x[:,5]\n",
    "plt.xticks(range(0, len(bpm),int(len(bpm)/20)))\n",
    "plt.scatter(range(len(bpm)), bpm)\n",
    "plt.title(\"bpm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupların Anova İle İncelenmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupları sınıflandırmak arasında anlamlı fark var mı F-testi ve ANOVA incelenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( hit_lenght,y_)#.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.c_[hit_lenght,y_.astype(int)],columns=[\"hit_lenght\",\"difficulty\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova1_data = pd.DataFrame(np.c_[hit_lenght,y_.astype(int)],columns=[\"hit_lenght\",\"difficulty\"])\n",
    "pg.anova(data=anova1_data,dv='hit_lenght',between='difficulty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult değerleri arasında p değeri 0.05 den küçük olduğu için anlamlı fark vardır yani bu grupların veriyi etkilediği söylenebilir. Tüm gruplar kendi içinde etkilimi söylemek için t test uygulanır. Bunun için pairwise_tukey test kullanılır ve gruplar kendi içinde incelenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova1_data,dv='hit_lenght',between='difficulty').head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tukey testinden uzak olan gruplar arasında daha anlamlı fark vardı bu ordinal veri olmasından dolayıdır. Uzak verilerden anlamlı bilgi çıkabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( cs, y_ )\n",
    "plt.title(\"Difficulty-Circle Size Relation\")\n",
    "plt.xlabel(\"Circle Size\")\n",
    "plt.ylabel(\"Difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova2_data = pd.DataFrame(np.c_[cs,y_.astype(int)],columns=[\"circle size\",\"difficulty\"])\n",
    "pg.anova(data=anova2_data, dv='circle size', between='difficulty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult değerleri arasında p değeri 0.05 den küçük olduğu için anlamlı fark vardır yani bu grupların veriyi etkilediği söylenebilir. Tüm gruplar kendi içinde etkilimi söylemek için t test uygulanır. Bunun için pairwise_tukey test kullanılır ve gruplar kendi içinde incelenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova2_data,dv='circle size',between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( drain, y_ )\n",
    "plt.title(\"Difficulty-Drain Relation\")\n",
    "plt.xlabel(\"Drain\")\n",
    "plt.ylabel(\"Difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova3_data = pd.DataFrame(np.c_[drain, y_.astype(int)], columns=[\"drain\",\"difficulty\"])\n",
    "pg.anova(data=anova3_data, dv='drain', between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova3_data, dv='drain',between='difficulty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova Devamı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( ar, y_ )\n",
    "plt.title(\"Difficulty-Approach Rate Relation\")\n",
    "plt.xlabel(\"Approach Rate\")\n",
    "plt.ylabel(\"Difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova4_data = pd.DataFrame(np.c_[ar, y_.astype(int)],columns=[\"approach rate\",\"difficulty\"])\n",
    "pg.anova(data=anova4_data, dv='approach rate', between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova4_data, dv='approach rate',between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( bpm, y_ )\n",
    "plt.title(\"Difficulty-bpm Relation\")\n",
    "plt.xlabel(\"bpm\")\n",
    "plt.ylabel(\"difficulty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova5_data = pd.DataFrame(np.c_[ar, y_.astype(int)],columns=[\"bpm\",\"difficulty\"])\n",
    "pg.anova(data=anova5_data, dv='bpm', between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova5_data, dv='bpm',between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( acc, y_ )\n",
    "plt.title(\"Difficulty Drain Relation\")\n",
    "plt.xlabel(\"accuracy\")\n",
    "plt.ylabel(\"difficult\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova6_data = pd.DataFrame(np.c_[ar, y_.astype(int)],columns=[\"accuracy\",\"difficulty\"])\n",
    "pg.anova(data=anova6_data, dv='accuracy', between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova6_data, dv='accuracy',between='difficulty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Way ANOVA incelemesi sonucu gereksiz verilerin atılmasına karar verilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x, columns=['hit_length','cs','drain','ar','accuracy','bpm']).boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12-11-10-9-0 zorluk değerlerinden anlamlı veri çıkmamaktadır bu yüzden yeterli veri toplanana kadar bu veri atılır.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult_count = [np.count_nonzero(anova3_data['difficulty'] == i) for i in range(int(np.max(anova3_data['difficulty'])))]\n",
    "plt.bar(range(len(difficult_count)),difficult_count,color ='maroon',width = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficult_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gereksiz Verinin Atılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.c_[x,y]\n",
    "reduced_ds=dataset[dataset[:,6] >= 1]\n",
    "reduced_ds=reduced_ds[reduced_ds[:,6] < 9]\n",
    "np.min(reduced_ds[:,6]), np.max(reduced_ds[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reduced_ds[:,:6]\n",
    "y = reduced_ds[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_data = pd.DataFrame(np.c_[x[:,0], y.astype(int)],columns=[\"hit_length\",\"difficulty\"])\n",
    "pg.anova(data=anova_data, dv='hit_length', between='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_tukey(data=anova_data, dv='hit_length',between='difficulty').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazır Modeller İle Deneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _x,_y 0 12 arası zorluk için || x,y 0 8 arası zorluk için\n",
    "models = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(), BayesianRidge(), SVR()]\n",
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    results.append(cross_val_score(model, x, y, cv = 10).sum() / 10)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 dan fonksiyonlar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean Distance\n",
    "def eucledian(p1,p2):\n",
    "    dist = np.sqrt(np.sum((p1-p2)**2))\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "#Function to calculate KNN\n",
    "def predict(x_train, y , x_input, k):\n",
    "    op_labels = []\n",
    "     \n",
    "    #Loop through the Datapoints to be classified\n",
    "    for item in x_input: \n",
    "         \n",
    "        #Array to store distances\n",
    "        point_dist = []\n",
    "         \n",
    "        #Loop through each training Data\n",
    "        for j in range(len(x_train)): \n",
    "            distances = eucledian(np.array(x_train[j,:]) , item) \n",
    "            #Calculating the distance\n",
    "            point_dist.append(distances) \n",
    "        point_dist = np.array(point_dist) \n",
    "         \n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        dist = np.argsort(point_dist)[:k] \n",
    "         \n",
    "        #Labels of the K datapoints from above\n",
    "        labels = y[dist]\n",
    "         \n",
    "        #Majority voting\n",
    "        lab = mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        op_labels.append(lab)\n",
    " \n",
    "    return op_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x[int(0.75*len(x)):]\n",
    "y_test = y[int(0.75*len(x)):].astype(int)\n",
    "y_train =  y[:int(0.75*len(x))].astype(int)\n",
    "x_train = x[:int(0.75*len(x))]\n",
    "y_pred = predict(x_train, y_train, x_test, 7)\n",
    "\n",
    "#Checking the accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Regresyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train\n",
    "X_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X_train, 0)\n",
    "sigma = np.std(X_train, 0)\n",
    "\n",
    "X_train = (X_train - mu ) / sigma\n",
    "\n",
    "#We use the same mean and SD as the one of X_train as we dont know the mean of X_test\n",
    "X_test = (X_test - mu ) / sigma\n",
    "\n",
    "#Standardizing the y_train data\n",
    "mu_y = np.mean(y_train, 0)\n",
    "sigma_y = np.std(y_train, 0, ddof = 0)\n",
    "\n",
    "y_train = (y_train - mu_y ) / sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized approach to find the \n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "# We are setting a range of K values and calculating the RMSE for each of them. This way we can chose the optimal K value\n",
    "k_list = [x for x in range(1,50,1)]\n",
    "\n",
    "# Calculating the distance matrix using numpy broadcasting technique \n",
    "distance = np.sqrt(((X_train[:, :, None] - X_test[:, :, None].T) ** 2).sum(1))\n",
    "\n",
    "#Sorting each data points of the distance matrix to reduce computational effort \n",
    "sorted_distance = np.argsort(distance, axis = 0)\n",
    "\n",
    "#The knn function takes in the sorted distance and returns the RMSE of the \n",
    "def knn(X_train,X_test,y_train,y_test,sorted_distance,k):\n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    for row in range(len(X_test)):\n",
    "        \n",
    "        #Transforming the y_train values to adjust the scale. \n",
    "        y_pred[row] = y_train[sorted_distance[:,row][:k]].mean() * sigma_y + mu_y\n",
    "\n",
    "    RMSE = np.sqrt(np.mean((y_test - y_pred)**2))\n",
    "    return RMSE\n",
    "\n",
    "#Storing the RMSE values in a list for each k value \n",
    "rmse_list = []\n",
    "for i in k_list:\n",
    "    rmse_list.append(knn(X_train,X_test,y_train,y_test,sorted_distance,i))\n",
    "    \n",
    "print(time.process_time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_list, rmse_list)\n",
    "plt.xlabel(\"K values\")\n",
    "plt.ylabel(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the optimal K value\n",
    "min_rmse_k_value = k_list[rmse_list.index(min(rmse_list))]\n",
    "\n",
    "#Finding the lowest possible RMSE\n",
    "optimal_RMSE = knn(X_train,X_test,y_train,y_test,sorted_distance,min_rmse_k_value)\n",
    "optimal_RMSE / (np.max(y)-np.min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse_k_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineer Ağırlıklı Regresyon (Kendimiz Yazdık)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "class LR():\n",
    "\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.iterations = iterations\n",
    "\n",
    "    # Function for model training\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # no_of_training_examples, no_of_features\n",
    "\n",
    "        self.m, self.n = X.shape\n",
    "\n",
    "        # weight initialization\n",
    "\n",
    "        self.W = np.zeros(self.n)\n",
    "\n",
    "        self.b = 0\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        self.Y = Y\n",
    "\n",
    "        # gradient descent learning\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "\n",
    "            self.update_weights()\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Helper function to update weights in gradient descent\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        Y_pred = self.predict(self.X)\n",
    "\n",
    "        # calculate gradients\n",
    "\n",
    "        dW = - (2 * (self.X.T).dot(self.Y - Y_pred)) / self.m\n",
    "\n",
    "        db = - 2 * np.sum(self.Y - Y_pred) / self.m\n",
    "\n",
    "        # update weights\n",
    "\n",
    "        self.W = self.W - self.learning_rate * dW\n",
    "\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Hypothetical function  h( x )\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        return X.dot(self.W) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LR(iterations=1000, learning_rate=0.01)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        res.append(r2_score(y_test, y_pred))\n",
    "\n",
    "np.array(res).sum() / 10"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31114ee4c0a5c1652c3f229edfa0c825ea27b625704175c6f57d7152219a4654"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
